{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3da0fa-8683-4548-96e2-6d5d8aeccc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d3112-7feb-4c75-b653-65b7c025e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansType(ans):\n",
    "    if ans == 'yes-no':\n",
    "        return ['yes', 'no']\n",
    "    elif is_number(ans):\n",
    "        return 'number'\n",
    "    elif ans in [\"cube\", \"sphere\", \"cylinder\"] :\n",
    "        return 'shape'\n",
    "    elif ans in  [\"small\", \"large\"]:\n",
    "        return 'size'\n",
    "    elif ans in [ \"left\", \"right\", \"behind\", \"front\"]:\n",
    "        return 'relation'\n",
    "    elif ans in [ \"gray\", \"red\", \"blue\", \"green\", \"brown\", \"purple\", \"cyan\", \"yellow\"]:\n",
    "        return 'colour'\n",
    "    elif ans in [\"rubber\", \"metal\"]:\n",
    "        return 'material'\n",
    "    \n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2597264e-bd9d-4dab-9b5b-7de7c38dfe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_filename': 'CLEVR_val_000012.png', 'question_index': 121, 'answer_type': 'colour', 'question': 'What is the color of the rubber cube?', 'ground_truth': 'red', 'model_generated_answer': 'red', 'consistent': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# image_path = '/scratch/nmachav1/CLEVR_v1.0/images/val/'\n",
    "# model = InstructBlipForConditionalGeneration.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
    "# processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n",
    "\n",
    "image_path = '/scratch/nmachav1/CLEVR_v1.0/images/val/'\n",
    "#object_type = ['inter', 'intra']\n",
    "for i in range(3,4):\n",
    "    dataset = f'/scratch/nmachav1/MLLM_Hallucinations_CLEVR/dataset/object_number_split/val_num_{i}.json'\n",
    "    #output_path = f'/scratch/nmachav1/MLLM_Hallucinations_CLEVR/outputs/InstructBLIP/val_num_{i}.json'\n",
    "    #dataset = f'/scratch/nmachav1/MLLM_Hallucinations_CLEVR/dataset/object_type_split/val_type_{i}.json'\n",
    "    #output_path = f'/scratch/nmachav1/MLLM_Hallucinations_CLEVR/outputs/LLaVA/val_type_{i}.json'\n",
    "    with open(dataset, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    complete_data = []\n",
    "    for each in tqdm(data[6:7]):\n",
    "        each_copy = each.copy()\n",
    "        img = Image.open(image_path+each['image_filename']).convert(\"RGB\")\n",
    "        prompt = each['question'] + 'Choose one of the following: gray, blue, brown, cyan, yellow, purple, red.'\n",
    "        inputs = processor(images=img, text=prompt, return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            use_cache=True,\n",
    "            num_beams=5,\n",
    "            max_length=256,\n",
    "            min_length=1,\n",
    "            top_p=1.0,\n",
    "            repetition_penalty=1.0,\n",
    "            length_penalty=1,\n",
    "            top_k=50,\n",
    "            temperature=1e-05\n",
    "        )\n",
    "        generated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "        each_copy['model_generated_answer'] = generated_text\n",
    "        print(each_copy)\n",
    "        #complete_data.append(each_copy)\n",
    "\n",
    "\n",
    "    # with open(output_path, 'w') as f:\n",
    "    #     json.dump(complete_data, f ,indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ac286-c758-4527-b327-1a626cd03e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5410a-c48b-4c80-be33-f359ffe24810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
